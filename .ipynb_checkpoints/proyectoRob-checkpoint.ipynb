{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#no olvida instalar las librerias como tensorflow y sklearn\n",
    "# pip install tensorflow\n",
    "#pip install sklearn\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D \n",
    "from keras.layers.core import Activation, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.metrics import AUC\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib\n",
    "from datetime import datetime\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        # first set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(6, (5, 5), padding=\"same\",input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # second set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(16, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(120))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(84))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "#cargar data y relacionados\n",
    "dataset = \"D:/cursos/robotica/w14/PID/BD/\"\n",
    "labs = \"D:/cursos/robotica/w14/PID/salidas2_ultra.csv\"\n",
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "EPOCHS = 30\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "index = []\n",
    "\n",
    "#leer la data y chocolatear\n",
    "\n",
    "imgpath = list(paths.list_files(dataset))\n",
    "index = list(range(len(imgpath)))\n",
    "labels = np.fromfile(labs,dtype=int,sep=\"\\n\",count=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle elements \n",
    "random.seed(datetime.now())\n",
    "for i in range(100):\n",
    "    random.shuffle(index)\n",
    "    \n",
    "#transform to np.array to shuffle\n",
    "imgpath = np.array(imgpath)[index]\n",
    "labels = np.array(labels)[index] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to load images\n",
    "data = []\n",
    "for i in imgpath:\n",
    "    #load image\n",
    "    image = cv2.imread(i)\n",
    "    image = cv2.resize(image,(32,32))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "#scaling\n",
    "data = np.array(data,dtype=\"float\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = to_categorical(trainY,num_classes=4)\n",
    "testY = to_categorical(testY, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Train on 8857 samples, validate on 2953 samples\n",
      "Epoch 1/30\n",
      "8857/8857 [==============================] - 7s 791us/step - loss: 0.2475 - accuracy: 0.9143 - val_loss: 0.2234 - val_accuracy: 0.9229\n",
      "Epoch 2/30\n",
      "8857/8857 [==============================] - 2s 282us/step - loss: 0.2300 - accuracy: 0.9169 - val_loss: 0.2103 - val_accuracy: 0.9235\n",
      "Epoch 3/30\n",
      "8857/8857 [==============================] - 3s 286us/step - loss: 0.2227 - accuracy: 0.9194 - val_loss: 0.2014 - val_accuracy: 0.9247\n",
      "Epoch 4/30\n",
      "8857/8857 [==============================] - 3s 283us/step - loss: 0.2167 - accuracy: 0.9189 - val_loss: 0.1958 - val_accuracy: 0.9291\n",
      "Epoch 5/30\n",
      "8857/8857 [==============================] - 3s 286us/step - loss: 0.2083 - accuracy: 0.9225 - val_loss: 0.1950 - val_accuracy: 0.9280\n",
      "Epoch 6/30\n",
      "8857/8857 [==============================] - 2s 275us/step - loss: 0.2033 - accuracy: 0.9233 - val_loss: 0.1918 - val_accuracy: 0.9308\n",
      "Epoch 7/30\n",
      "8857/8857 [==============================] - 2s 273us/step - loss: 0.2000 - accuracy: 0.9240 - val_loss: 0.1867 - val_accuracy: 0.9300\n",
      "Epoch 8/30\n",
      "8857/8857 [==============================] - 2s 272us/step - loss: 0.1963 - accuracy: 0.9252 - val_loss: 0.1846 - val_accuracy: 0.9296\n",
      "Epoch 9/30\n",
      "8857/8857 [==============================] - 2s 272us/step - loss: 0.1942 - accuracy: 0.9260 - val_loss: 0.1814 - val_accuracy: 0.9318\n",
      "Epoch 10/30\n",
      "8857/8857 [==============================] - 2s 279us/step - loss: 0.1909 - accuracy: 0.9258 - val_loss: 0.1845 - val_accuracy: 0.9318\n",
      "Epoch 11/30\n",
      "8857/8857 [==============================] - 3s 284us/step - loss: 0.1886 - accuracy: 0.9269 - val_loss: 0.1800 - val_accuracy: 0.9344\n",
      "Epoch 12/30\n",
      "8857/8857 [==============================] - 3s 289us/step - loss: 0.1868 - accuracy: 0.9281 - val_loss: 0.1794 - val_accuracy: 0.9326\n",
      "Epoch 13/30\n",
      "8857/8857 [==============================] - 2s 274us/step - loss: 0.1839 - accuracy: 0.9295 - val_loss: 0.1793 - val_accuracy: 0.9346\n",
      "Epoch 14/30\n",
      "8857/8857 [==============================] - 2s 280us/step - loss: 0.1824 - accuracy: 0.9298 - val_loss: 0.1804 - val_accuracy: 0.9358\n",
      "Epoch 15/30\n",
      "8857/8857 [==============================] - 2s 278us/step - loss: 0.1818 - accuracy: 0.9310 - val_loss: 0.1812 - val_accuracy: 0.9315\n",
      "Epoch 16/30\n",
      "8857/8857 [==============================] - 2s 278us/step - loss: 0.1795 - accuracy: 0.9303 - val_loss: 0.1748 - val_accuracy: 0.9365\n",
      "Epoch 17/30\n",
      "8857/8857 [==============================] - 2s 281us/step - loss: 0.1775 - accuracy: 0.9307 - val_loss: 0.1791 - val_accuracy: 0.9336\n",
      "Epoch 18/30\n",
      "8857/8857 [==============================] - 2s 276us/step - loss: 0.1741 - accuracy: 0.9325 - val_loss: 0.1777 - val_accuracy: 0.9336\n",
      "Epoch 19/30\n",
      "8857/8857 [==============================] - 3s 315us/step - loss: 0.1729 - accuracy: 0.9323 - val_loss: 0.1740 - val_accuracy: 0.9356\n",
      "Epoch 20/30\n",
      "8857/8857 [==============================] - 3s 288us/step - loss: 0.1721 - accuracy: 0.9324 - val_loss: 0.1768 - val_accuracy: 0.9314\n",
      "Epoch 21/30\n",
      "8857/8857 [==============================] - 3s 284us/step - loss: 0.1703 - accuracy: 0.9319 - val_loss: 0.1730 - val_accuracy: 0.9352\n",
      "Epoch 22/30\n",
      "8857/8857 [==============================] - 3s 302us/step - loss: 0.1686 - accuracy: 0.9327 - val_loss: 0.1789 - val_accuracy: 0.9349\n",
      "Epoch 23/30\n",
      "8857/8857 [==============================] - 3s 294us/step - loss: 0.1667 - accuracy: 0.9335 - val_loss: 0.1711 - val_accuracy: 0.9366\n",
      "Epoch 24/30\n",
      "8857/8857 [==============================] - 2s 275us/step - loss: 0.1651 - accuracy: 0.9329 - val_loss: 0.1737 - val_accuracy: 0.9355\n",
      "Epoch 25/30\n",
      "8857/8857 [==============================] - 2s 278us/step - loss: 0.1625 - accuracy: 0.9334 - val_loss: 0.1708 - val_accuracy: 0.9378\n",
      "Epoch 26/30\n",
      "8857/8857 [==============================] - 2s 271us/step - loss: 0.1614 - accuracy: 0.9341 - val_loss: 0.1664 - val_accuracy: 0.9391\n",
      "Epoch 27/30\n",
      "8857/8857 [==============================] - 2s 275us/step - loss: 0.1595 - accuracy: 0.9343 - val_loss: 0.1671 - val_accuracy: 0.9350\n",
      "Epoch 28/30\n",
      "8857/8857 [==============================] - 2s 279us/step - loss: 0.1579 - accuracy: 0.9346 - val_loss: 0.1701 - val_accuracy: 0.9342\n",
      "Epoch 29/30\n",
      "8857/8857 [==============================] - 2s 273us/step - loss: 0.1553 - accuracy: 0.9354 - val_loss: 0.1690 - val_accuracy: 0.9378\n",
      "Epoch 30/30\n",
      "8857/8857 [==============================] - 2s 271us/step - loss: 0.1537 - accuracy: 0.9349 - val_loss: 0.1676 - val_accuracy: 0.9347\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=32, height=32, depth=3, classes=4)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,  metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(trainX, trainY, batch_size=BS, validation_data=(testX, testY),# steps_per_epoch=len(trainX) // BS,\n",
    " epochs=EPOCHS, verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"modelrobotica\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
